#!/bin/bash
# Continuous Quality Monitoring Setup
# Establishes ongoing monitoring for platform quality metrics

set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"

echo "üìä Setting up Continuous Quality Monitoring..."
echo "=============================================="

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m'

cd "$PROJECT_ROOT"

# Create monitoring directories
echo -e "${BLUE}üìÅ Creating monitoring directory structure...${NC}"
mkdir -p monitoring/dashboards
mkdir -p monitoring/alerts
mkdir -p monitoring/metrics
mkdir -p monitoring/logs
mkdir -p monitoring/config

# Quality Metrics Collection Script
echo -e "${BLUE}üìà Creating quality metrics collector...${NC}"
cat > monitoring/collect-quality-metrics.sh << 'EOF'
#!/bin/bash
# Quality Metrics Collection Script
# Collects and stores quality metrics for trending analysis

set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

TIMESTAMP=$(date -Iseconds)
METRICS_FILE="$SCRIPT_DIR/metrics/quality-metrics-$(date +%Y-%m-%d-%H%M).json"

cd "$PROJECT_ROOT"

echo "üìä Collecting quality metrics at $TIMESTAMP"

# Initialize metrics object
cat > "$METRICS_FILE" << EOF
{
  "timestamp": "$TIMESTAMP",
  "metrics": {
EOF

# Test Coverage Metrics
echo "Collecting test coverage..."
if npm run test:coverage:json > /dev/null 2>&1; then
    COVERAGE=$(cat coverage/coverage-summary.json 2>/dev/null || echo '{"total":{"lines":{"pct":0},"statements":{"pct":0},"functions":{"pct":0},"branches":{"pct":0}}}')
    echo "    \"testCoverage\": $COVERAGE," >> "$METRICS_FILE"
else
    echo "    \"testCoverage\": {\"total\":{\"lines\":{\"pct\":0},\"statements\":{\"pct\":0},\"functions\":{\"pct\":0},\"branches\":{\"pct\":0}}}," >> "$METRICS_FILE"
fi

# Performance Metrics
echo "Collecting performance metrics..."
DASHBOARD_LOAD_TIME=$(curl -w '%{time_total}' -o /dev/null -s http://localhost:3000 2>/dev/null || echo "0")
API_RESPONSE_TIME=$(curl -w '%{time_total}' -o /dev/null -s http://localhost:8000/api/v1/health 2>/dev/null || echo "0")

cat >> "$METRICS_FILE" << EOF
    "performance": {
      "dashboardLoadTime": $DASHBOARD_LOAD_TIME,
      "apiResponseTime": $API_RESPONSE_TIME,
      "unit": "seconds"
    },
EOF

# Security Metrics
echo "Collecting security metrics..."
VULNERABILITIES=$(npm audit --json 2>/dev/null | jq '.metadata.vulnerabilities' 2>/dev/null || echo '{"total":0,"low":0,"moderate":0,"high":0,"critical":0}')

cat >> "$METRICS_FILE" << EOF
    "security": {
      "vulnerabilities": $VULNERABILITIES
    },
EOF

# Business Logic Test Results
echo "Collecting business logic test results..."
COMMISSION_TESTS=$(npm test -- --testNamePattern='commission' --json 2>/dev/null | jq '{numPassedTests: .numPassedTests, numFailedTests: .numFailedTests}' 2>/dev/null || echo '{"numPassedTests":0,"numFailedTests":0}')
PIPELINE_TESTS=$(npm test -- --testNamePattern='pipeline' --json 2>/dev/null | jq '{numPassedTests: .numPassedTests, numFailedTests: .numFailedTests}' 2>/dev/null || echo '{"numPassedTests":0,"numFailedTests":0}')

cat >> "$METRICS_FILE" << EOF
    "businessLogic": {
      "commissionTests": $COMMISSION_TESTS,
      "pipelineTests": $PIPELINE_TESTS
    },
EOF

# Code Quality Metrics
echo "Collecting code quality metrics..."
LINT_ERRORS=$(npm run lint 2>&1 | grep -c "error" || echo "0")
TYPE_ERRORS=$(npm run type-check 2>&1 | grep -c "error" || echo "0")

cat >> "$METRICS_FILE" << EOF
    "codeQuality": {
      "lintErrors": $LINT_ERRORS,
      "typeErrors": $TYPE_ERRORS
    },
EOF

# System Health Metrics
echo "Collecting system health metrics..."
DOCKER_STATUS=$(docker-compose ps 2>/dev/null | grep -c "Up" || echo "0")
DB_STATUS=$(timeout 5 npm run test:db:ping > /dev/null 2>&1 && echo "1" || echo "0")

cat >> "$METRICS_FILE" << EOF
    "systemHealth": {
      "dockerServicesUp": $DOCKER_STATUS,
      "databaseConnectable": $DB_STATUS
    }
EOF

# Close metrics object
cat >> "$METRICS_FILE" << EOF
  }
}
EOF

echo "‚úÖ Metrics collected: $METRICS_FILE"

# Calculate quality score
QUALITY_SCORE=$(node -e "
const metrics = require('$METRICS_FILE');
let score = 0;

// Test coverage (30 points)
const coverage = metrics.metrics.testCoverage.total.lines.pct || 0;
score += Math.min(30, coverage * 0.3);

// Performance (20 points)
const dashTime = parseFloat(metrics.metrics.performance.dashboardLoadTime);
const apiTime = parseFloat(metrics.metrics.performance.apiResponseTime);
if (dashTime < 2) score += 10;
if (apiTime < 0.5) score += 10;

// Security (20 points)
const vulns = metrics.metrics.security.vulnerabilities;
if (vulns.high === 0 && vulns.critical === 0) score += 20;
else if (vulns.critical === 0) score += 10;

// Business logic (20 points)
const commTests = metrics.metrics.businessLogic.commissionTests;
const pipeTests = metrics.metrics.businessLogic.pipelineTests;
if (commTests.numFailedTests === 0) score += 10;
if (pipeTests.numFailedTests === 0) score += 10;

// Code quality (10 points)
if (metrics.metrics.codeQuality.lintErrors === 0) score += 5;
if (metrics.metrics.codeQuality.typeErrors === 0) score += 5;

console.log(Math.round(score));
")

echo "Quality Score: $QUALITY_SCORE/100"
EOF

chmod +x monitoring/collect-quality-metrics.sh

# Quality Alerting System
echo -e "${BLUE}üö® Creating quality alerting system...${NC}"
cat > monitoring/quality-alerts.sh << 'EOF'
#!/bin/bash
# Quality Alerting System
# Monitors quality metrics and sends alerts when thresholds are breached

set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Load latest metrics
LATEST_METRICS=$(find "$SCRIPT_DIR/metrics" -name "quality-metrics-*.json" -type f | sort | tail -1)

if [ ! -f "$LATEST_METRICS" ]; then
    echo "No metrics found - skipping alerts"
    exit 0
fi

echo "üìä Checking quality alerts from: $LATEST_METRICS"

# Extract key metrics
COVERAGE=$(jq -r '.metrics.testCoverage.total.lines.pct // 0' "$LATEST_METRICS")
DASHBOARD_TIME=$(jq -r '.metrics.performance.dashboardLoadTime // 0' "$LATEST_METRICS")
API_TIME=$(jq -r '.metrics.performance.apiResponseTime // 0' "$LATEST_METRICS")
HIGH_VULNS=$(jq -r '.metrics.security.vulnerabilities.high // 0' "$LATEST_METRICS")
CRITICAL_VULNS=$(jq -r '.metrics.security.vulnerabilities.critical // 0' "$LATEST_METRICS")
COMMISSION_FAILURES=$(jq -r '.metrics.businessLogic.commissionTests.numFailedTests // 0' "$LATEST_METRICS")
PIPELINE_FAILURES=$(jq -r '.metrics.businessLogic.pipelineTests.numFailedTests // 0' "$LATEST_METRICS")

ALERTS=()

# Coverage alerts
if (( $(echo "$COVERAGE < 90" | bc -l) )); then
    ALERTS+=("‚ö†Ô∏è Test coverage below 90%: ${COVERAGE}%")
fi

# Performance alerts
if (( $(echo "$DASHBOARD_TIME > 2" | bc -l) )); then
    ALERTS+=("üêå Dashboard load time exceeds 2s: ${DASHBOARD_TIME}s")
fi

if (( $(echo "$API_TIME > 0.5" | bc -l) )); then
    ALERTS+=("üêå API response time exceeds 500ms: ${API_TIME}s")
fi

# Security alerts
if [ "$CRITICAL_VULNS" -gt 0 ]; then
    ALERTS+=("üö® CRITICAL: ${CRITICAL_VULNS} critical vulnerabilities found")
fi

if [ "$HIGH_VULNS" -gt 0 ]; then
    ALERTS+=("‚ö†Ô∏è ${HIGH_VULNS} high-severity vulnerabilities found")
fi

# Business logic alerts
if [ "$COMMISSION_FAILURES" -gt 0 ]; then
    ALERTS+=("üí∞ CRITICAL: Commission calculation tests failing: ${COMMISSION_FAILURES}")
fi

if [ "$PIPELINE_FAILURES" -gt 0 ]; then
    ALERTS+=("üìà CRITICAL: Pipeline management tests failing: ${PIPELINE_FAILURES}")
fi

# Send alerts if any found
if [ ${#ALERTS[@]} -gt 0 ]; then
    echo "üö® Quality Alerts Detected:"
    for alert in "${ALERTS[@]}"; do
        echo "  $alert"
    done

    # Log to alerts file
    ALERT_FILE="$SCRIPT_DIR/alerts/alert-$(date +%Y-%m-%d-%H%M).txt"
    {
        echo "Quality Alert - $(date)"
        echo "========================"
        for alert in "${ALERTS[@]}"; do
            echo "$alert"
        done
        echo ""
        echo "Metrics file: $LATEST_METRICS"
    } > "$ALERT_FILE"

    # Send notification (customize as needed)
    echo "Alert logged to: $ALERT_FILE"

    # Example integrations (uncomment and configure as needed):
    # Send email alert
    # echo "Quality alerts detected" | mail -s "Partnership Platform QA Alert" vp@company.com

    # Send Slack notification
    # curl -X POST -H 'Content-type: application/json' \
    #   --data '{"text":"Quality alerts in Partnership Platform"}' \
    #   YOUR_SLACK_WEBHOOK_URL

    exit 1
else
    echo "‚úÖ No quality alerts - all metrics within thresholds"
    exit 0
fi
EOF

chmod +x monitoring/quality-alerts.sh

# Quality Dashboard Generator
echo -e "${BLUE}üìä Creating quality dashboard generator...${NC}"
cat > monitoring/generate-dashboard.sh << 'EOF'
#!/bin/bash
# Quality Dashboard Generator
# Creates HTML dashboard from quality metrics

set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

echo "üìä Generating Quality Dashboard..."

# Collect latest metrics
LATEST_METRICS=$(find "$SCRIPT_DIR/metrics" -name "quality-metrics-*.json" -type f | sort | tail -1)

if [ ! -f "$LATEST_METRICS" ]; then
    echo "No metrics found - creating empty dashboard"
    LATEST_METRICS="/dev/null"
fi

# Generate HTML dashboard
cat > "$SCRIPT_DIR/dashboards/quality-dashboard.html" << 'HTML'
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Partnership Platform - Quality Dashboard</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
        .header { text-align: center; margin-bottom: 30px; }
        .metrics-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
        .metric-card { background: white; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .metric-title { font-size: 18px; font-weight: bold; margin-bottom: 10px; color: #333; }
        .metric-value { font-size: 24px; font-weight: bold; }
        .status-good { color: #4CAF50; }
        .status-warning { color: #FF9800; }
        .status-error { color: #F44336; }
        .progress-bar { width: 100%; height: 20px; background: #eee; border-radius: 10px; overflow: hidden; margin: 10px 0; }
        .progress-fill { height: 100%; border-radius: 10px; transition: width 0.3s ease; }
        .timestamp { text-align: center; margin-top: 20px; color: #666; font-size: 14px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>üéØ Partnership Management Platform</h1>
        <h2>Quality Dashboard</h2>
    </div>

    <div class="metrics-grid">
        <!-- Test Coverage -->
        <div class="metric-card">
            <div class="metric-title">üìä Test Coverage</div>
            <div class="metric-value status-good" id="coverage-value">Loading...</div>
            <div class="progress-bar">
                <div class="progress-fill status-good" id="coverage-bar" style="width: 0%;"></div>
            </div>
        </div>

        <!-- Performance -->
        <div class="metric-card">
            <div class="metric-title">‚ö° Performance</div>
            <div style="margin: 10px 0;">
                Dashboard: <span class="metric-value" id="dashboard-time">Loading...</span>
            </div>
            <div style="margin: 10px 0;">
                API: <span class="metric-value" id="api-time">Loading...</span>
            </div>
        </div>

        <!-- Security -->
        <div class="metric-card">
            <div class="metric-title">üîí Security</div>
            <div style="margin: 10px 0;">
                Critical: <span class="metric-value" id="critical-vulns">Loading...</span>
            </div>
            <div style="margin: 10px 0;">
                High: <span class="metric-value" id="high-vulns">Loading...</span>
            </div>
        </div>

        <!-- Business Logic -->
        <div class="metric-card">
            <div class="metric-title">üíº Business Logic</div>
            <div style="margin: 10px 0;">
                Commission Tests: <span class="metric-value" id="commission-status">Loading...</span>
            </div>
            <div style="margin: 10px 0;">
                Pipeline Tests: <span class="metric-value" id="pipeline-status">Loading...</span>
            </div>
        </div>

        <!-- Overall Health -->
        <div class="metric-card">
            <div class="metric-title">üè• Overall Health</div>
            <div class="metric-value" id="health-score">Loading...</div>
            <div class="progress-bar">
                <div class="progress-fill" id="health-bar" style="width: 0%;"></div>
            </div>
        </div>

        <!-- System Status -->
        <div class="metric-card">
            <div class="metric-title">üê≥ System Status</div>
            <div style="margin: 10px 0;">
                Docker: <span class="metric-value" id="docker-status">Loading...</span>
            </div>
            <div style="margin: 10px 0;">
                Database: <span class="metric-value" id="db-status">Loading...</span>
            </div>
        </div>
    </div>

    <div class="timestamp" id="last-updated">Last updated: Loading...</div>

    <script>
        // Load metrics and update dashboard
        function loadMetrics() {
            // In a real implementation, this would fetch from an API
            // For now, we'll update with placeholder data

            // Mock data - replace with actual metrics loading
            const mockMetrics = {
                testCoverage: { total: { lines: { pct: 92 } } },
                performance: { dashboardLoadTime: 1.2, apiResponseTime: 0.3 },
                security: { vulnerabilities: { critical: 0, high: 1 } },
                businessLogic: {
                    commissionTests: { numFailedTests: 0 },
                    pipelineTests: { numFailedTests: 0 }
                },
                systemHealth: { dockerServicesUp: 5, databaseConnectable: 1 }
            };

            updateDashboard(mockMetrics);
        }

        function updateDashboard(metrics) {
            // Test Coverage
            const coverage = metrics.testCoverage.total.lines.pct;
            document.getElementById('coverage-value').textContent = coverage + '%';
            document.getElementById('coverage-bar').style.width = coverage + '%';
            document.getElementById('coverage-value').className =
                coverage >= 90 ? 'metric-value status-good' :
                coverage >= 75 ? 'metric-value status-warning' : 'metric-value status-error';

            // Performance
            const dashTime = metrics.performance.dashboardLoadTime;
            const apiTime = metrics.performance.apiResponseTime;
            document.getElementById('dashboard-time').textContent = dashTime + 's';
            document.getElementById('api-time').textContent = apiTime + 's';
            document.getElementById('dashboard-time').className =
                dashTime < 2 ? 'metric-value status-good' : 'metric-value status-error';
            document.getElementById('api-time').className =
                apiTime < 0.5 ? 'metric-value status-good' : 'metric-value status-error';

            // Security
            const critical = metrics.security.vulnerabilities.critical;
            const high = metrics.security.vulnerabilities.high;
            document.getElementById('critical-vulns').textContent = critical;
            document.getElementById('high-vulns').textContent = high;
            document.getElementById('critical-vulns').className =
                critical === 0 ? 'metric-value status-good' : 'metric-value status-error';
            document.getElementById('high-vulns').className =
                high === 0 ? 'metric-value status-good' : 'metric-value status-warning';

            // Business Logic
            const commFailed = metrics.businessLogic.commissionTests.numFailedTests;
            const pipeFailed = metrics.businessLogic.pipelineTests.numFailedTests;
            document.getElementById('commission-status').textContent =
                commFailed === 0 ? '‚úÖ Passing' : '‚ùå ' + commFailed + ' Failed';
            document.getElementById('pipeline-status').textContent =
                pipeFailed === 0 ? '‚úÖ Passing' : '‚ùå ' + pipeFailed + ' Failed';

            // Overall Health (calculated)
            let healthScore = 0;
            if (coverage >= 90) healthScore += 25;
            if (dashTime < 2) healthScore += 20;
            if (apiTime < 0.5) healthScore += 20;
            if (critical === 0 && high === 0) healthScore += 20;
            if (commFailed === 0 && pipeFailed === 0) healthScore += 15;

            document.getElementById('health-score').textContent = healthScore + '/100';
            document.getElementById('health-bar').style.width = healthScore + '%';
            document.getElementById('health-bar').className =
                healthScore >= 80 ? 'progress-fill status-good' :
                healthScore >= 60 ? 'progress-fill status-warning' : 'progress-fill status-error';

            // System Status
            document.getElementById('docker-status').textContent =
                metrics.systemHealth.dockerServicesUp > 0 ? '‚úÖ Running' : '‚ùå Down';
            document.getElementById('db-status').textContent =
                metrics.systemHealth.databaseConnectable ? '‚úÖ Connected' : '‚ùå Disconnected';

            // Timestamp
            document.getElementById('last-updated').textContent =
                'Last updated: ' + new Date().toLocaleString();
        }

        // Load metrics on page load
        loadMetrics();

        // Auto-refresh every 30 seconds
        setInterval(loadMetrics, 30000);
    </script>
</body>
</html>
HTML

echo "‚úÖ Quality dashboard generated: $SCRIPT_DIR/dashboards/quality-dashboard.html"
EOF

chmod +x monitoring/generate-dashboard.sh

# Monitoring configuration
echo -e "${BLUE}‚öôÔ∏è Creating monitoring configuration...${NC}"
cat > monitoring/config/monitoring.json << 'EOF'
{
  "qualityThresholds": {
    "testCoverage": {
      "minimum": 90,
      "warning": 85,
      "critical": 75
    },
    "performance": {
      "dashboardLoadTime": {
        "warning": 2.0,
        "critical": 3.0
      },
      "apiResponseTime": {
        "warning": 0.5,
        "critical": 1.0
      }
    },
    "security": {
      "criticalVulnerabilities": 0,
      "highVulnerabilities": 3
    },
    "businessLogic": {
      "allowedFailures": 0
    }
  },
  "alerting": {
    "email": {
      "enabled": false,
      "recipients": ["vp@company.com", "dev-team@company.com"]
    },
    "slack": {
      "enabled": false,
      "webhook": "YOUR_SLACK_WEBHOOK_URL"
    }
  },
  "reporting": {
    "dailyReports": true,
    "weeklyReports": true,
    "monthlyReports": true
  }
}
EOF

# Monitoring startup script
echo -e "${BLUE}üöÄ Creating monitoring startup script...${NC}"
cat > monitoring/start-monitoring.sh << 'EOF'
#!/bin/bash
# Start Quality Monitoring System

set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

echo "üöÄ Starting Quality Monitoring System..."

# Collect initial metrics
echo "üìä Collecting initial metrics..."
./collect-quality-metrics.sh

# Generate dashboard
echo "üìä Generating quality dashboard..."
./generate-dashboard.sh

# Check for alerts
echo "üö® Checking for quality alerts..."
./quality-alerts.sh || echo "Alerts found - check alerts directory"

# Start monitoring daemon (runs every 15 minutes)
echo "üîÑ Starting monitoring daemon..."
(
    while true; do
        sleep 900  # 15 minutes
        echo "$(date): Running scheduled quality check..."
        ./collect-quality-metrics.sh
        ./generate-dashboard.sh
        ./quality-alerts.sh || echo "$(date): Quality alerts detected"
    done
) &

MONITOR_PID=$!
echo $MONITOR_PID > monitoring.pid

echo "‚úÖ Quality monitoring started (PID: $MONITOR_PID)"
echo "üìä Dashboard available at: file://$(pwd)/dashboards/quality-dashboard.html"
echo "üõë To stop monitoring: kill $(cat monitoring.pid)"
EOF

chmod +x monitoring/start-monitoring.sh

# Stop monitoring script
cat > monitoring/stop-monitoring.sh << 'EOF'
#!/bin/bash
# Stop Quality Monitoring System

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

if [ -f "$SCRIPT_DIR/monitoring.pid" ]; then
    PID=$(cat "$SCRIPT_DIR/monitoring.pid")
    echo "üõë Stopping quality monitoring (PID: $PID)..."
    kill $PID 2>/dev/null || echo "Process already stopped"
    rm -f "$SCRIPT_DIR/monitoring.pid"
    echo "‚úÖ Quality monitoring stopped"
else
    echo "‚ùå No monitoring process found"
fi
EOF

chmod +x monitoring/stop-monitoring.sh

# Integration with package.json
echo -e "${BLUE}üì¶ Adding monitoring scripts to package.json...${NC}"
if [ -f package.json ]; then
    node -e "
    const fs = require('fs');
    const pkg = JSON.parse(fs.readFileSync('package.json', 'utf8'));

    pkg.scripts = pkg.scripts || {};

    // Monitoring scripts
    pkg.scripts['monitor:start'] = './monitoring/start-monitoring.sh';
    pkg.scripts['monitor:stop'] = './monitoring/stop-monitoring.sh';
    pkg.scripts['monitor:metrics'] = './monitoring/collect-quality-metrics.sh';
    pkg.scripts['monitor:dashboard'] = './monitoring/generate-dashboard.sh';
    pkg.scripts['monitor:alerts'] = './monitoring/quality-alerts.sh';

    fs.writeFileSync('package.json', JSON.stringify(pkg, null, 2));
    "
    echo "‚úÖ Monitoring scripts added to package.json"
fi

# Create initial health check
echo -e "${BLUE}üè• Running initial quality health check...${NC}"
./monitoring/collect-quality-metrics.sh
./monitoring/generate-dashboard.sh

echo -e "\nüéâ Continuous Quality Monitoring Setup Complete!"
echo "================================================="
echo ""
echo -e "${GREEN}‚úÖ Monitoring infrastructure configured${NC}"
echo -e "${GREEN}‚úÖ Quality metrics collection enabled${NC}"
echo -e "${GREEN}‚úÖ Alerting system configured${NC}"
echo -e "${GREEN}‚úÖ Quality dashboard available${NC}"
echo ""
echo -e "${BLUE}üöÄ Quick Start:${NC}"
echo "  npm run monitor:start    # Start continuous monitoring"
echo "  npm run monitor:metrics  # Collect metrics manually"
echo "  npm run monitor:dashboard # Generate dashboard"
echo "  npm run monitor:alerts   # Check for alerts"
echo "  npm run monitor:stop     # Stop monitoring"
echo ""
echo -e "${PURPLE}üìä Dashboard will be available at:${NC}"
echo "  file://$(pwd)/monitoring/dashboards/quality-dashboard.html"
echo ""
echo -e "${YELLOW}üí° Monitoring Features:${NC}"
echo "  ‚Ä¢ Automatic metrics collection every 15 minutes"
echo "  ‚Ä¢ Real-time quality dashboard"
echo "  ‚Ä¢ Proactive alerting on quality degradation"
echo "  ‚Ä¢ Trend analysis and reporting"
echo "  ‚Ä¢ Business logic validation monitoring"
echo ""
echo -e "${BLUE}üéØ Your \$250K revenue platform now has continuous quality monitoring!${NC}"